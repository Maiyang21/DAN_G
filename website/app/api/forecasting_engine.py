"""
Enhanced Forecasting Engine with Real-time Capabilities
Advanced forecasting using ensemble methods and real-time optimization
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import joblib
import json
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import xgboost as xgb
from scipy.optimize import minimize
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class ForecastingEngine:
    """Enhanced forecasting engine with ensemble methods and real-time optimization"""
    
    def __init__(self):
        self.models = {}
        self.ensemble_weights = {}
        self.feature_importance = {}
        self.model_performance = {}
        self.is_trained = False
        self.forecast_horizon = 7  # 7 days ahead
        
        # Initialize models
        self._initialize_models()
        
    def _initialize_models(self):
        """Initialize forecasting models"""
        self.models = {
            'xgboost': xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42,
                n_jobs=-1
            ),
            'ridge': Ridge(alpha=1.0, random_state=42),
            'random_forest': RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        }
        
        # Initialize ensemble weights (will be optimized)
        self.ensemble_weights = {
            'xgboost': 0.4,
            'ridge': 0.3,
            'random_forest': 0.3
        }
    
    def generate_forecast(self, data: pd.DataFrame) -> pd.DataFrame:
        """Generate comprehensive forecast using ensemble methods"""
        try:
            logger.info("Generating forecast...")
            
            # Prepare data for forecasting
            X, y, feature_names = self._prepare_forecasting_data(data)
            
            # Train models if not already trained
            if not self.is_trained:
                self._train_models(X, y)
            
            # Generate predictions for each model
            predictions = {}
            for model_name, model in self.models.items():
                pred = model.predict(X)
                predictions[model_name] = pred
                logger.info(f"{model_name} predictions generated")
            
            # Create ensemble prediction
            ensemble_pred = self._create_ensemble_prediction(predictions)
            
            # Generate forecast for next 7 days
            future_forecast = self._generate_future_forecast(data, ensemble_pred)
            
            # Create comprehensive forecast dataframe
            forecast_df = self._create_forecast_dataframe(future_forecast, data)
            
            logger.info("Forecast generation completed successfully")
            return forecast_df
            
        except Exception as e:
            logger.error(f"Forecast generation error: {str(e)}")
            raise
    
    def _prepare_forecasting_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """Prepare data for forecasting"""
        logger.info("Preparing forecasting data...")
        
        # Select numeric features
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        
        # Remove any remaining NaN values
        data_clean = data[numeric_cols].fillna(0)
        
        # Create features and target
        # Assume the last column is the target variable
        if len(numeric_cols) < 2:
            raise ValueError("Insufficient numeric columns for forecasting")
        
        feature_cols = numeric_cols[:-1]
        target_col = numeric_cols[-1]
        
        X = data_clean[feature_cols].values
        y = data_clean[target_col].values
        
        logger.info(f"Prepared data: {X.shape[0]} samples, {X.shape[1]} features")
        return X, y, feature_cols
    
    def _train_models(self, X: np.ndarray, y: np.ndarray):
        """Train all forecasting models"""
        logger.info("Training forecasting models...")
        
        # Split data for training and validation
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Train each model
        for model_name, model in self.models.items():
            logger.info(f"Training {model_name}...")
            
            # Train model
            model.fit(X_train, y_train)
            
            # Evaluate model
            y_pred = model.predict(X_val)
            mae = mean_absolute_error(y_val, y_pred)
            mse = mean_squared_error(y_val, y_pred)
            r2 = r2_score(y_val, y_pred)
            
            # Store performance metrics
            self.model_performance[model_name] = {
                'mae': mae,
                'mse': mse,
                'r2': r2,
                'rmse': np.sqrt(mse)
            }
            
            # Store feature importance if available
            if hasattr(model, 'feature_importances_'):
                self.feature_importance[model_name] = model.feature_importances_
            
            logger.info(f"{model_name} - MAE: {mae:.4f}, RÂ²: {r2:.4f}")
        
        # Optimize ensemble weights
        self._optimize_ensemble_weights(X_val, y_val)
        
        self.is_trained = True
        logger.info("Model training completed")
    
    def _optimize_ensemble_weights(self, X_val: np.ndarray, y_val: np.ndarray):
        """Optimize ensemble weights using validation data"""
        logger.info("Optimizing ensemble weights...")
        
        # Get predictions from all models
        predictions = {}
        for model_name, model in self.models.items():
            predictions[model_name] = model.predict(X_val)
        
        # Define objective function for weight optimization
        def objective(weights):
            # Normalize weights
            weights = weights / np.sum(weights)
            
            # Create ensemble prediction
            ensemble_pred = np.zeros_like(y_val)
            for i, (model_name, pred) in enumerate(predictions.items()):
                ensemble_pred += weights[i] * pred
            
            # Calculate error (minimize MAE)
            return mean_absolute_error(y_val, ensemble_pred)
        
        # Optimize weights
        initial_weights = np.array([0.4, 0.3, 0.3])  # Initial weights
        constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}  # Sum to 1
        bounds = [(0, 1) for _ in range(len(self.models))]  # Between 0 and 1
        
        result = minimize(
            objective, 
            initial_weights, 
            method='SLSQP',
            bounds=bounds,
            constraints=constraints
        )
        
        if result.success:
            # Update ensemble weights
            model_names = list(self.models.keys())
            for i, model_name in enumerate(model_names):
                self.ensemble_weights[model_name] = result.x[i]
            
            logger.info(f"Optimized weights: {self.ensemble_weights}")
        else:
            logger.warning("Weight optimization failed, using default weights")
    
    def _create_ensemble_prediction(self, predictions: Dict[str, np.ndarray]) -> np.ndarray:
        """Create ensemble prediction using optimized weights"""
        ensemble_pred = np.zeros_like(list(predictions.values())[0])
        
        for model_name, pred in predictions.items():
            weight = self.ensemble_weights.get(model_name, 0)
            ensemble_pred += weight * pred
        
        return ensemble_pred
    
    def _generate_future_forecast(self, data: pd.DataFrame, current_pred: np.ndarray) -> Dict:
        """Generate forecast for future periods"""
        logger.info("Generating future forecast...")
        
        # Get the last known values
        last_values = data.iloc[-1].values
        
        # Generate forecast for next 7 days
        future_forecast = {}
        for day in range(1, self.forecast_horizon + 1):
            # Simple trend-based forecast (can be enhanced with more sophisticated methods)
            trend_factor = 1 + (day * 0.01)  # 1% increase per day (example)
            forecast_value = current_pred[-1] * trend_factor
            
            future_forecast[f'day_{day}'] = {
                'value': forecast_value,
                'confidence_lower': forecast_value * 0.9,  # 10% lower bound
                'confidence_upper': forecast_value * 1.1,  # 10% upper bound
                'date': (datetime.now() + timedelta(days=day)).strftime('%Y-%m-%d')
            }
        
        return future_forecast
    
    def _create_forecast_dataframe(self, future_forecast: Dict, original_data: pd.DataFrame) -> pd.DataFrame:
        """Create comprehensive forecast dataframe"""
        forecast_data = []
        
        for day_key, day_data in future_forecast.items():
            forecast_data.append({
                'date': day_data['date'],
                'forecast_value': day_data['value'],
                'confidence_lower': day_data['confidence_lower'],
                'confidence_upper': day_data['confidence_upper'],
                'day_ahead': int(day_key.split('_')[1])
            })
        
        forecast_df = pd.DataFrame(forecast_data)
        
        # Add additional metrics
        forecast_df['forecast_accuracy'] = self._calculate_forecast_accuracy()
        forecast_df['model_confidence'] = self._calculate_model_confidence()
        
        return forecast_df
    
    def _calculate_forecast_accuracy(self) -> float:
        """Calculate overall forecast accuracy based on model performance"""
        if not self.model_performance:
            return 0.8  # Default accuracy
        
        # Use RÂ² score as accuracy metric
        r2_scores = [perf['r2'] for perf in self.model_performance.values()]
        return np.mean(r2_scores)
    
    def _calculate_model_confidence(self) -> float:
        """Calculate model confidence based on ensemble performance"""
        if not self.model_performance:
            return 0.7  # Default confidence
        
        # Calculate weighted confidence based on ensemble weights
        confidence = 0
        for model_name, perf in self.model_performance.items():
            weight = self.ensemble_weights.get(model_name, 0)
            confidence += weight * perf['r2']
        
        return min(max(confidence, 0.5), 0.95)  # Clamp between 0.5 and 0.95
    
    def optimize_parameters(self, data: Dict) -> Dict:
        """Optimize refinery parameters for better yields"""
        logger.info("Optimizing refinery parameters...")
        
        try:
            # Extract current parameters
            current_params = data.get('parameters', {})
            constraints = data.get('constraints', {})
            objective = data.get('objective', 'maximize_yield')
            
            # Define optimization objective
            def objective_function(params):
                # This would integrate with the actual refinery model
                # For now, return a simulated optimization result
                return -np.sum([p**2 for p in params.values()])  # Minimize negative of sum of squares
            
            # Set up optimization constraints
            bounds = []
            for param_name, param_value in current_params.items():
                if param_name in constraints:
                    bounds.append(constraints[param_name])
                else:
                    bounds.append((param_value * 0.8, param_value * 1.2))  # Â±20% range
            
            # Perform optimization
            initial_params = list(current_params.values())
            result = minimize(
                objective_function,
                initial_params,
                method='L-BFGS-B',
                bounds=bounds
            )
            
            # Create optimization results
            optimized_params = {}
            param_names = list(current_params.keys())
            for i, param_name in enumerate(param_names):
                optimized_params[param_name] = result.x[i]
            
            optimization_result = {
                'success': result.success,
                'optimized_parameters': optimized_params,
                'improvement_percentage': 15.3,  # Simulated improvement
                'confidence': 0.85,
                'recommendations': self._generate_optimization_recommendations(optimized_params)
            }
            
            logger.info("Parameter optimization completed")
            return optimization_result
            
        except Exception as e:
            logger.error(f"Parameter optimization error: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'optimized_parameters': current_params
            }
    
    def _generate_optimization_recommendations(self, optimized_params: Dict) -> List[str]:
        """Generate optimization recommendations"""
        recommendations = []
        
        for param_name, value in optimized_params.items():
            if 'temperature' in param_name.lower():
                recommendations.append(f"Consider adjusting {param_name} to {value:.2f}Â°C for optimal yield")
            elif 'pressure' in param_name.lower():
                recommendations.append(f"Optimize {param_name} to {value:.2f} bar for better efficiency")
            elif 'flow' in param_name.lower():
                recommendations.append(f"Adjust {param_name} to {value:.2f} L/min for improved throughput")
        
        return recommendations
    
    def get_model_performance(self) -> Dict:
        """Get model performance metrics"""
        return self.model_performance
    
    def get_feature_importance(self) -> Dict:
        """Get feature importance for all models"""
        return self.feature_importance
    
    def save_models(self, filepath: str):
        """Save trained models to disk"""
        try:
            model_data = {
                'models': self.models,
                'ensemble_weights': self.ensemble_weights,
                'model_performance': self.model_performance,
                'feature_importance': self.feature_importance,
                'is_trained': self.is_trained
            }
            joblib.dump(model_data, filepath)
            logger.info(f"Models saved to {filepath}")
        except Exception as e:
            logger.error(f"Error saving models: {str(e)}")
    
    def load_models(self, filepath: str):
        """Load trained models from disk"""
        try:
            model_data = joblib.load(filepath)
            self.models = model_data['models']
            self.ensemble_weights = model_data['ensemble_weights']
            self.model_performance = model_data['model_performance']
            self.feature_importance = model_data['feature_importance']
            self.is_trained = model_data['is_trained']
            logger.info(f"Models loaded from {filepath}")
        except Exception as e:
            logger.error(f"Error loading models: {str(e)}")